{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:24.870677Z","iopub.execute_input":"2025-06-25T08:04:24.870976Z","iopub.status.idle":"2025-06-25T08:04:24.876565Z","shell.execute_reply.started":"2025-06-25T08:04:24.870954Z","shell.execute_reply":"2025-06-25T08:04:24.875439Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Load Titanic dataset from seaborn\ndf = sns.load_dataset('titanic')\n\n# Check structure\nprint(df.head())\nprint(df.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:24.877843Z","iopub.execute_input":"2025-06-25T08:04:24.878108Z","iopub.status.idle":"2025-06-25T08:04:24.917960Z","shell.execute_reply.started":"2025-06-25T08:04:24.878079Z","shell.execute_reply":"2025-06-25T08:04:24.916888Z"}},"outputs":[{"name":"stdout","text":"   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n0         0       3    male  22.0      1      0   7.2500        S  Third   \n1         1       1  female  38.0      1      0  71.2833        C  First   \n2         1       3  female  26.0      0      0   7.9250        S  Third   \n3         1       1  female  35.0      1      0  53.1000        S  First   \n4         0       3    male  35.0      0      0   8.0500        S  Third   \n\n     who  adult_male deck  embark_town alive  alone  \n0    man        True  NaN  Southampton    no  False  \n1  woman       False    C    Cherbourg   yes  False  \n2  woman       False  NaN  Southampton   yes   True  \n3  woman       False    C  Southampton   yes  False  \n4    man        True  NaN  Southampton    no   True  \nsurvived         0\npclass           0\nsex              0\nage            177\nsibsp            0\nparch            0\nfare             0\nembarked         2\nclass            0\nwho              0\nadult_male       0\ndeck           688\nembark_town      2\nalive            0\nalone            0\ndtype: int64\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Drop irrelevant or high-missing-value columns\ndf = df.drop(['deck', 'embark_town', 'alive', 'who', 'adult_male', 'class'], axis=1)\n\n# Drop rows with missing values in 'embarked', 'age', or 'embarked'\ndf = df.dropna(subset=['age', 'embarked'])\n\n# Fill missing 'embarked' if needed (already dropped above)\ndf['embarked'] = LabelEncoder().fit_transform(df['embarked'])\ndf['sex'] = LabelEncoder().fit_transform(df['sex'])\n\n# Drop 'survived' from features, store it as target\nX = df.drop(['survived'], axis=1)\ny = df['survived']\n\n# Drop any remaining object columns (e.g., 'sibsp' and 'parch' are already numerical)\nX = X.select_dtypes(include=[np.number])\n\n# Scale numeric features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:24.919630Z","iopub.execute_input":"2025-06-25T08:04:24.919970Z","iopub.status.idle":"2025-06-25T08:04:24.941612Z","shell.execute_reply.started":"2025-06-25T08:04:24.919945Z","shell.execute_reply":"2025-06-25T08:04:24.940577Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(16, input_dim=X.shape[1], activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:24.942548Z","iopub.execute_input":"2025-06-25T08:04:24.943028Z","iopub.status.idle":"2025-06-25T08:04:25.012094Z","shell.execute_reply.started":"2025-06-25T08:04:24.943000Z","shell.execute_reply":"2025-06-25T08:04:25.010577Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:25.014396Z","iopub.execute_input":"2025-06-25T08:04:25.014666Z","iopub.status.idle":"2025-06-25T08:04:25.027647Z","shell.execute_reply.started":"2025-06-25T08:04:25.014646Z","shell.execute_reply":"2025-06-25T08:04:25.026175Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:25.028797Z","iopub.execute_input":"2025-06-25T08:04:25.029206Z","iopub.status.idle":"2025-06-25T08:04:41.068006Z","shell.execute_reply.started":"2025-06-25T08:04:25.029167Z","shell.execute_reply":"2025-06-25T08:04:41.067235Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.5232 - loss: 0.6964 - val_accuracy: 0.7105 - val_loss: 0.6783\nEpoch 2/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6909 - loss: 0.6777 - val_accuracy: 0.6842 - val_loss: 0.6665\nEpoch 3/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6616 - loss: 0.6680 - val_accuracy: 0.6491 - val_loss: 0.6522\nEpoch 4/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6614 - loss: 0.6492 - val_accuracy: 0.6579 - val_loss: 0.6335\nEpoch 5/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6771 - loss: 0.6326 - val_accuracy: 0.6579 - val_loss: 0.6138\nEpoch 6/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6674 - loss: 0.6152 - val_accuracy: 0.6579 - val_loss: 0.5955\nEpoch 7/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6714 - loss: 0.5893 - val_accuracy: 0.6667 - val_loss: 0.5806\nEpoch 8/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7024 - loss: 0.5702 - val_accuracy: 0.6842 - val_loss: 0.5692\nEpoch 9/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7064 - loss: 0.5557 - val_accuracy: 0.7018 - val_loss: 0.5585\nEpoch 10/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7566 - loss: 0.5406 - val_accuracy: 0.7368 - val_loss: 0.5499\nEpoch 11/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.5436 - val_accuracy: 0.7456 - val_loss: 0.5427\nEpoch 12/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7946 - loss: 0.5177 - val_accuracy: 0.7719 - val_loss: 0.5334\nEpoch 13/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8012 - loss: 0.5099 - val_accuracy: 0.7807 - val_loss: 0.5244\nEpoch 14/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8229 - loss: 0.4910 - val_accuracy: 0.7895 - val_loss: 0.5149\nEpoch 15/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8377 - loss: 0.4767 - val_accuracy: 0.7807 - val_loss: 0.5062\nEpoch 16/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8059 - loss: 0.5047 - val_accuracy: 0.7807 - val_loss: 0.4998\nEpoch 17/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8178 - loss: 0.4681 - val_accuracy: 0.7807 - val_loss: 0.4943\nEpoch 18/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8042 - loss: 0.4648 - val_accuracy: 0.7895 - val_loss: 0.4848\nEpoch 19/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8036 - loss: 0.4558 - val_accuracy: 0.7895 - val_loss: 0.4756\nEpoch 20/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8349 - loss: 0.4243 - val_accuracy: 0.7895 - val_loss: 0.4692\nEpoch 21/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8444 - loss: 0.4127 - val_accuracy: 0.7807 - val_loss: 0.4645\nEpoch 22/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8109 - loss: 0.4418 - val_accuracy: 0.7807 - val_loss: 0.4613\nEpoch 23/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8291 - loss: 0.4387 - val_accuracy: 0.7807 - val_loss: 0.4556\nEpoch 24/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.4225 - val_accuracy: 0.7895 - val_loss: 0.4530\nEpoch 25/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8425 - loss: 0.3988 - val_accuracy: 0.7895 - val_loss: 0.4512\nEpoch 26/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.4166 - val_accuracy: 0.7895 - val_loss: 0.4514\nEpoch 27/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.4278 - val_accuracy: 0.7895 - val_loss: 0.4478\nEpoch 28/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8373 - loss: 0.4022 - val_accuracy: 0.7982 - val_loss: 0.4415\nEpoch 29/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8438 - loss: 0.3883 - val_accuracy: 0.7982 - val_loss: 0.4397\nEpoch 30/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8273 - loss: 0.4070 - val_accuracy: 0.7982 - val_loss: 0.4393\nEpoch 31/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8492 - loss: 0.3989 - val_accuracy: 0.8070 - val_loss: 0.4357\nEpoch 32/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8457 - loss: 0.3800 - val_accuracy: 0.7895 - val_loss: 0.4380\nEpoch 33/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8529 - loss: 0.3711 - val_accuracy: 0.7982 - val_loss: 0.4423\nEpoch 34/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8171 - loss: 0.3935 - val_accuracy: 0.7895 - val_loss: 0.4401\nEpoch 35/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8302 - loss: 0.4224 - val_accuracy: 0.7895 - val_loss: 0.4424\nEpoch 36/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8311 - loss: 0.3777 - val_accuracy: 0.7895 - val_loss: 0.4394\nEpoch 37/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8469 - loss: 0.3696 - val_accuracy: 0.7982 - val_loss: 0.4367\nEpoch 38/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8154 - loss: 0.3829 - val_accuracy: 0.8070 - val_loss: 0.4315\nEpoch 39/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8492 - loss: 0.3630 - val_accuracy: 0.7895 - val_loss: 0.4340\nEpoch 40/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8392 - loss: 0.3721 - val_accuracy: 0.7982 - val_loss: 0.4336\nEpoch 41/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8422 - loss: 0.3777 - val_accuracy: 0.7982 - val_loss: 0.4324\nEpoch 42/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8505 - loss: 0.3623 - val_accuracy: 0.7895 - val_loss: 0.4332\nEpoch 43/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8416 - loss: 0.4038 - val_accuracy: 0.7895 - val_loss: 0.4372\nEpoch 44/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8374 - loss: 0.4013 - val_accuracy: 0.7807 - val_loss: 0.4368\nEpoch 45/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8201 - loss: 0.3949 - val_accuracy: 0.7807 - val_loss: 0.4338\nEpoch 46/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8262 - loss: 0.4201 - val_accuracy: 0.7807 - val_loss: 0.4353\nEpoch 47/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8527 - loss: 0.3553 - val_accuracy: 0.7807 - val_loss: 0.4340\nEpoch 48/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8368 - loss: 0.3869 - val_accuracy: 0.7807 - val_loss: 0.4286\nEpoch 49/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.4050 - val_accuracy: 0.7807 - val_loss: 0.4305\nEpoch 50/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8522 - loss: 0.3718 - val_accuracy: 0.7719 - val_loss: 0.4399\nEpoch 51/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8427 - loss: 0.3763 - val_accuracy: 0.7719 - val_loss: 0.4347\nEpoch 52/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8474 - loss: 0.3918 - val_accuracy: 0.7719 - val_loss: 0.4319\nEpoch 53/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8223 - loss: 0.3872 - val_accuracy: 0.7807 - val_loss: 0.4314\nEpoch 54/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8633 - loss: 0.3624 - val_accuracy: 0.7719 - val_loss: 0.4318\nEpoch 55/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8342 - loss: 0.3961 - val_accuracy: 0.7807 - val_loss: 0.4281\nEpoch 56/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8373 - loss: 0.3816 - val_accuracy: 0.7719 - val_loss: 0.4301\nEpoch 57/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8488 - loss: 0.3718 - val_accuracy: 0.7895 - val_loss: 0.4286\nEpoch 58/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8469 - loss: 0.3971 - val_accuracy: 0.7895 - val_loss: 0.4296\nEpoch 59/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8326 - loss: 0.4116 - val_accuracy: 0.7895 - val_loss: 0.4273\nEpoch 60/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8396 - loss: 0.3710 - val_accuracy: 0.7632 - val_loss: 0.4324\nEpoch 61/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8585 - loss: 0.3479 - val_accuracy: 0.7719 - val_loss: 0.4324\nEpoch 62/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8429 - loss: 0.3785 - val_accuracy: 0.7807 - val_loss: 0.4324\nEpoch 63/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8529 - loss: 0.3672 - val_accuracy: 0.7807 - val_loss: 0.4254\nEpoch 64/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8643 - loss: 0.3589 - val_accuracy: 0.7807 - val_loss: 0.4287\nEpoch 65/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8395 - loss: 0.3903 - val_accuracy: 0.7807 - val_loss: 0.4279\nEpoch 66/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8535 - loss: 0.3471 - val_accuracy: 0.7719 - val_loss: 0.4323\nEpoch 67/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8539 - loss: 0.3621 - val_accuracy: 0.7719 - val_loss: 0.4327\nEpoch 68/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8406 - loss: 0.3808 - val_accuracy: 0.7719 - val_loss: 0.4322\nEpoch 69/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8543 - loss: 0.3505 - val_accuracy: 0.7719 - val_loss: 0.4327\nEpoch 70/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8496 - loss: 0.3958 - val_accuracy: 0.7719 - val_loss: 0.4323\nEpoch 71/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8352 - loss: 0.4007 - val_accuracy: 0.7719 - val_loss: 0.4294\nEpoch 72/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8207 - loss: 0.4065 - val_accuracy: 0.7719 - val_loss: 0.4277\nEpoch 73/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8595 - loss: 0.3731 - val_accuracy: 0.7895 - val_loss: 0.4336\nEpoch 74/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 0.3823 - val_accuracy: 0.7719 - val_loss: 0.4332\nEpoch 75/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8393 - loss: 0.3857 - val_accuracy: 0.7719 - val_loss: 0.4247\nEpoch 76/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8547 - loss: 0.3353 - val_accuracy: 0.7719 - val_loss: 0.4233\nEpoch 77/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 0.3793 - val_accuracy: 0.7719 - val_loss: 0.4276\nEpoch 78/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8542 - loss: 0.3720 - val_accuracy: 0.7719 - val_loss: 0.4283\nEpoch 79/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8493 - loss: 0.3497 - val_accuracy: 0.7719 - val_loss: 0.4266\nEpoch 80/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8560 - loss: 0.3476 - val_accuracy: 0.7719 - val_loss: 0.4288\nEpoch 81/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8697 - loss: 0.3433 - val_accuracy: 0.7719 - val_loss: 0.4260\nEpoch 82/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8445 - loss: 0.3668 - val_accuracy: 0.7719 - val_loss: 0.4223\nEpoch 83/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8452 - loss: 0.3849 - val_accuracy: 0.7895 - val_loss: 0.4291\nEpoch 84/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8506 - loss: 0.3768 - val_accuracy: 0.7895 - val_loss: 0.4327\nEpoch 85/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8508 - loss: 0.3588 - val_accuracy: 0.7895 - val_loss: 0.4307\nEpoch 86/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8552 - loss: 0.3721 - val_accuracy: 0.7895 - val_loss: 0.4264\nEpoch 87/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8786 - loss: 0.3435 - val_accuracy: 0.7895 - val_loss: 0.4312\nEpoch 88/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.3243 - val_accuracy: 0.7895 - val_loss: 0.4261\nEpoch 89/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8624 - loss: 0.3520 - val_accuracy: 0.7807 - val_loss: 0.4259\nEpoch 90/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8380 - loss: 0.4018 - val_accuracy: 0.7632 - val_loss: 0.4274\nEpoch 91/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8701 - loss: 0.3486 - val_accuracy: 0.7895 - val_loss: 0.4286\nEpoch 92/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.3282 - val_accuracy: 0.7895 - val_loss: 0.4291\nEpoch 93/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8487 - loss: 0.3815 - val_accuracy: 0.7895 - val_loss: 0.4302\nEpoch 94/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.3807 - val_accuracy: 0.7807 - val_loss: 0.4304\nEpoch 95/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8635 - loss: 0.3241 - val_accuracy: 0.7719 - val_loss: 0.4319\nEpoch 96/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8457 - loss: 0.3746 - val_accuracy: 0.7895 - val_loss: 0.4257\nEpoch 97/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8600 - loss: 0.3547 - val_accuracy: 0.7807 - val_loss: 0.4283\nEpoch 98/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8714 - loss: 0.3155 - val_accuracy: 0.7807 - val_loss: 0.4276\nEpoch 99/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8510 - loss: 0.3547 - val_accuracy: 0.7895 - val_loss: 0.4270\nEpoch 100/100\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8672 - loss: 0.3360 - val_accuracy: 0.7719 - val_loss: 0.4218\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"loss, accuracy = model.evaluate(X_test, y_test)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T08:04:41.069641Z","iopub.execute_input":"2025-06-25T08:04:41.069990Z","iopub.status.idle":"2025-06-25T08:04:41.192121Z","shell.execute_reply.started":"2025-06-25T08:04:41.069959Z","shell.execute_reply":"2025-06-25T08:04:41.191325Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8175 - loss: 0.4558 \nTest Accuracy: 0.8042\n","output_type":"stream"}],"execution_count":45}]}